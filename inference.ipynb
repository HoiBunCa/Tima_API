{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15e9af4b-2076-459d-904e-cb8b46a8ac67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model... Done! Took 3.2498295307159424 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "PATH_TO_CFG = \"pipeline.config\"\n",
    "# PATH_TO_CKPT = \"model/checkpoint\"\n",
    "\n",
    "print('Loading model... ', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore('model/ckpt-21').expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987bdda8-99cd-4d70-a3d8-76c65915f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "import time\n",
    "import cv2\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "PATH_TO_LABELS = \"label_map.pbtxt\"\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)\n",
    "\n",
    "# warnings.filterwarnings('ignore')\n",
    "def load_image_into_numpy_array(path):\n",
    "    return np.array(Image.open(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23a98687-030a-4ca1-8c16-196992214185",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import abc\n",
    "import collections\n",
    "# Set headless-friendly backend.\n",
    "import matplotlib; matplotlib.use('Agg')  # pylint: disable=multiple-statements\n",
    "import matplotlib.pyplot as plt  # pylint: disable=g-import-not-at-top\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import PIL.ImageColor as ImageColor\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import PIL.ImageFont as ImageFont\n",
    "import six\n",
    "from six.moves import range\n",
    "from six.moves import zip\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "from object_detection.core import keypoint_ops\n",
    "from object_detection.core import standard_fields as fields\n",
    "from object_detection.utils import shape_utils\n",
    "\n",
    "_TITLE_LEFT_MARGIN = 10\n",
    "_TITLE_TOP_MARGIN = 10\n",
    "STANDARD_COLORS = [\n",
    "    'AliceBlue', 'Chartreuse', 'Aqua', 'Aquamarine', 'Azure', 'Beige', 'Bisque',\n",
    "    'BlanchedAlmond', 'BlueViolet', 'BurlyWood', 'CadetBlue', 'AntiqueWhite',\n",
    "    'Chocolate', 'Coral', 'CornflowerBlue', 'Cornsilk', 'Crimson', 'Cyan',\n",
    "    'DarkCyan', 'DarkGoldenRod', 'DarkGrey', 'DarkKhaki', 'DarkOrange',\n",
    "    'DarkOrchid', 'DarkSalmon', 'DarkSeaGreen', 'DarkTurquoise', 'DarkViolet',\n",
    "    'DeepPink', 'DeepSkyBlue', 'DodgerBlue', 'FireBrick', 'FloralWhite',\n",
    "    'ForestGreen', 'Fuchsia', 'Gainsboro', 'GhostWhite', 'Gold', 'GoldenRod',\n",
    "    'Salmon', 'Tan', 'HoneyDew', 'HotPink', 'IndianRed', 'Ivory', 'Khaki',\n",
    "    'Lavender', 'LavenderBlush', 'LawnGreen', 'LemonChiffon', 'LightBlue',\n",
    "    'LightCoral', 'LightCyan', 'LightGoldenRodYellow', 'LightGray', 'LightGrey',\n",
    "    'LightGreen', 'LightPink', 'LightSalmon', 'LightSeaGreen', 'LightSkyBlue',\n",
    "    'LightSlateGray', 'LightSlateGrey', 'LightSteelBlue', 'LightYellow', 'Lime',\n",
    "    'LimeGreen', 'Linen', 'Magenta', 'MediumAquaMarine', 'MediumOrchid',\n",
    "    'MediumPurple', 'MediumSeaGreen', 'MediumSlateBlue', 'MediumSpringGreen',\n",
    "    'MediumTurquoise', 'MediumVioletRed', 'MintCream', 'MistyRose', 'Moccasin',\n",
    "    'NavajoWhite', 'OldLace', 'Olive', 'OliveDrab', 'Orange', 'OrangeRed',\n",
    "    'Orchid', 'PaleGoldenRod', 'PaleGreen', 'PaleTurquoise', 'PaleVioletRed',\n",
    "    'PapayaWhip', 'PeachPuff', 'Peru', 'Pink', 'Plum', 'PowderBlue', 'Purple',\n",
    "    'Red', 'RosyBrown', 'RoyalBlue', 'SaddleBrown', 'Green', 'SandyBrown',\n",
    "    'SeaGreen', 'SeaShell', 'Sienna', 'Silver', 'SkyBlue', 'SlateBlue',\n",
    "    'SlateGray', 'SlateGrey', 'Snow', 'SpringGreen', 'SteelBlue', 'GreenYellow',\n",
    "    'Teal', 'Thistle', 'Tomato', 'Turquoise', 'Violet', 'Wheat', 'White',\n",
    "    'WhiteSmoke', 'Yellow', 'YellowGreen'\n",
    "]\n",
    "def draw_box(\n",
    "    image,\n",
    "    boxes,\n",
    "    classes,\n",
    "    scores,\n",
    "    category_index,\n",
    "    instance_masks=None,\n",
    "    instance_boundaries=None,\n",
    "    keypoints=None,\n",
    "    keypoint_scores=None,\n",
    "    keypoint_edges=None,\n",
    "    track_ids=None,\n",
    "    use_normalized_coordinates=False,\n",
    "    max_boxes_to_draw=20,\n",
    "    min_score_thresh=.5,\n",
    "    agnostic_mode=False,\n",
    "    line_thickness=4,\n",
    "    mask_alpha=.4,\n",
    "    groundtruth_box_visualization_color='black',\n",
    "    skip_boxes=False,\n",
    "    skip_scores=False,\n",
    "    skip_labels=False,\n",
    "    skip_track_ids=False):\n",
    "\n",
    "  # Create a display string (and color) for every box location, group any boxes\n",
    "  # that correspond to the same location.\n",
    "  box_to_display_str_map = collections.defaultdict(list)\n",
    "  box_to_color_map = collections.defaultdict(str)\n",
    "  box_to_instance_masks_map = {}\n",
    "  box_to_instance_boundaries_map = {}\n",
    "  box_to_keypoints_map = collections.defaultdict(list)\n",
    "  box_to_keypoint_scores_map = collections.defaultdict(list)\n",
    "  box_to_track_ids_map = {}\n",
    "  if not max_boxes_to_draw:\n",
    "    max_boxes_to_draw = boxes.shape[0]\n",
    "  for i in range(boxes.shape[0]):\n",
    "    if max_boxes_to_draw == len(box_to_color_map):\n",
    "      break\n",
    "    if scores is None or scores[i] > min_score_thresh:\n",
    "      box = tuple(boxes[i].tolist())\n",
    "      if instance_masks is not None:\n",
    "        box_to_instance_masks_map[box] = instance_masks[i]\n",
    "      if instance_boundaries is not None:\n",
    "        box_to_instance_boundaries_map[box] = instance_boundaries[i]\n",
    "      if keypoints is not None:\n",
    "        box_to_keypoints_map[box].extend(keypoints[i])\n",
    "      if keypoint_scores is not None:\n",
    "        box_to_keypoint_scores_map[box].extend(keypoint_scores[i])\n",
    "      if track_ids is not None:\n",
    "        box_to_track_ids_map[box] = track_ids[i]\n",
    "      if scores is None:\n",
    "        box_to_color_map[box] = groundtruth_box_visualization_color\n",
    "      else:\n",
    "        display_str = ''\n",
    "        if not skip_labels:\n",
    "          if not agnostic_mode:\n",
    "            if classes[i] in six.viewkeys(category_index):\n",
    "              class_name = category_index[classes[i]]['name']\n",
    "            else:\n",
    "              class_name = 'N/A'\n",
    "            display_str = str(class_name)\n",
    "        if not skip_scores:\n",
    "          if not display_str:\n",
    "            display_str = '{}%'.format(round(100*scores[i]))\n",
    "          else:\n",
    "            display_str = '{}: {}%'.format(display_str, round(100*scores[i]))\n",
    "        if not skip_track_ids and track_ids is not None:\n",
    "          if not display_str:\n",
    "            display_str = 'ID {}'.format(track_ids[i])\n",
    "          else:\n",
    "            display_str = '{}: ID {}'.format(display_str, track_ids[i])\n",
    "        box_to_display_str_map[box].append(display_str)\n",
    "        if agnostic_mode:\n",
    "          box_to_color_map[box] = 'DarkOrange'\n",
    "        elif track_ids is not None:\n",
    "          prime_multipler = _get_multiplier_for_color_randomness()\n",
    "          box_to_color_map[box] = STANDARD_COLORS[\n",
    "              (prime_multipler * track_ids[i]) % len(STANDARD_COLORS)]\n",
    "        else:\n",
    "          box_to_color_map[box] = STANDARD_COLORS[\n",
    "              classes[i] % len(STANDARD_COLORS)]\n",
    "\n",
    "  # Draw all boxes onto image.\n",
    "  for box, color in box_to_color_map.items():\n",
    "    \n",
    "    ymin, xmin, ymax, xmax = box\n",
    "    if instance_masks is not None:\n",
    "      draw_mask_on_image_array(\n",
    "          image,\n",
    "          box_to_instance_masks_map[box],\n",
    "          color=color,\n",
    "          alpha=mask_alpha\n",
    "      )\n",
    "    if instance_boundaries is not None:\n",
    "      draw_mask_on_image_array(\n",
    "          image,\n",
    "          box_to_instance_boundaries_map[box],\n",
    "          color='red',\n",
    "          alpha=1.0\n",
    "      )\n",
    "    BBB = draw_bounding_box_on_image_array(\n",
    "        image,\n",
    "        ymin,\n",
    "        xmin,\n",
    "        ymax,\n",
    "        xmax,\n",
    "        color=color,\n",
    "        thickness=0 if skip_boxes else line_thickness,\n",
    "        display_str_list=box_to_display_str_map[box],\n",
    "        use_normalized_coordinates=use_normalized_coordinates)\n",
    "    \n",
    "    if keypoints is not None:\n",
    "      \n",
    "      keypoint_scores_for_box = None\n",
    "      if box_to_keypoint_scores_map:\n",
    "        keypoint_scores_for_box = box_to_keypoint_scores_map[box]\n",
    "      AAA = draw_keypoints_on_image_array(\n",
    "          image,\n",
    "          box_to_keypoints_map[box],\n",
    "          keypoint_scores_for_box,\n",
    "          min_score_thresh=min_score_thresh,\n",
    "          color=color,\n",
    "          radius=line_thickness / 2,\n",
    "          use_normalized_coordinates=use_normalized_coordinates,\n",
    "          keypoint_edges=keypoint_edges,\n",
    "          keypoint_edge_color=color,\n",
    "          keypoint_edge_width=line_thickness // 2)\n",
    "  try:\n",
    "      return image, AAA, BBB\n",
    "  except :\n",
    "      return image, [], []\n",
    "\n",
    "def draw_bounding_box_on_image_array(image,\n",
    "                                     ymin,\n",
    "                                     xmin,\n",
    "                                     ymax,\n",
    "                                     xmax,\n",
    "                                     color='red',\n",
    "                                     thickness=4,\n",
    "                                     display_str_list=(),\n",
    "                                     use_normalized_coordinates=True):\n",
    "\n",
    "  image_pil = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "  BBB = draw_bounding_box_on_image(image_pil, ymin, xmin, ymax, xmax, color,\n",
    "                             thickness, display_str_list,\n",
    "                             use_normalized_coordinates)\n",
    "  np.copyto(image, np.array(image_pil))\n",
    "  return BBB\n",
    "  \n",
    "\n",
    "def draw_bounding_box_on_image(image,\n",
    "                               ymin,\n",
    "                               xmin,\n",
    "                               ymax,\n",
    "                               xmax,\n",
    "                               color='red',\n",
    "                               thickness=4,\n",
    "                               display_str_list=(),\n",
    "                               use_normalized_coordinates=True):\n",
    "\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  if use_normalized_coordinates:\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                  ymin * im_height, ymax * im_height)\n",
    "  else:\n",
    "    (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n",
    "  if thickness > 0:\n",
    "    draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "               (left, top)],\n",
    "              width=thickness,\n",
    "              fill=color)\n",
    "  BBB = [int(left), int(top), int(right), int(bottom)]\n",
    "  try:\n",
    "    font = ImageFont.truetype('arial.ttf', 24)\n",
    "  except IOError:\n",
    "    font = ImageFont.load_default()\n",
    "\n",
    "  # If the total height of the display strings added to the top of the bounding\n",
    "  # box exceeds the top of the image, stack the strings below the bounding box\n",
    "  # instead of above.\n",
    "  display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "  # Each display_str has a top and bottom margin of 0.05x.\n",
    "  total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "  if top > total_display_str_height:\n",
    "    text_bottom = top\n",
    "  else:\n",
    "    text_bottom = bottom + total_display_str_height\n",
    "  # Reverse list and print from bottom to top.\n",
    "  for display_str in display_str_list[::-1]:\n",
    "    text_width, text_height = font.getsize(display_str)\n",
    "    margin = np.ceil(0.05 * text_height)\n",
    "    draw.rectangle(\n",
    "        [(left, text_bottom - text_height - 2 * margin), (left + text_width,\n",
    "                                                          text_bottom)],\n",
    "        fill=color)\n",
    "    draw.text(\n",
    "        (left + margin, text_bottom - text_height - margin),\n",
    "        display_str,\n",
    "        fill='black',\n",
    "        font=font)\n",
    "    text_bottom -= text_height - 2 * margin\n",
    "  \n",
    "  return BBB\n",
    "\n",
    "\n",
    "\n",
    "def draw_keypoints_on_image_array(image,\n",
    "                                  keypoints,\n",
    "                                  keypoint_scores=None,\n",
    "                                  min_score_thresh=0.5,\n",
    "                                  color='red',\n",
    "                                  radius=2,\n",
    "                                  use_normalized_coordinates=True,\n",
    "                                  keypoint_edges=None,\n",
    "                                  keypoint_edge_color='green',\n",
    "                                  keypoint_edge_width=2):\n",
    "\n",
    "  image_pil = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "  AAA = draw_keypoints_on_image(image_pil,\n",
    "                          keypoints,\n",
    "                          keypoint_scores=keypoint_scores,\n",
    "                          min_score_thresh=min_score_thresh,\n",
    "                          color=color,\n",
    "                          radius=radius,\n",
    "                          use_normalized_coordinates=use_normalized_coordinates,\n",
    "                          keypoint_edges=keypoint_edges,\n",
    "                          keypoint_edge_color=keypoint_edge_color,\n",
    "                          keypoint_edge_width=keypoint_edge_width)\n",
    "  np.copyto(image, np.array(image_pil))\n",
    "  return AAA\n",
    "\n",
    "\n",
    "def draw_keypoints_on_image(image,\n",
    "                            keypoints,\n",
    "                            keypoint_scores=None,\n",
    "                            min_score_thresh=0.5,\n",
    "                            color='red',\n",
    "                            radius=2,\n",
    "                            use_normalized_coordinates=True,\n",
    "                            keypoint_edges=None,\n",
    "                            keypoint_edge_color='green',\n",
    "                            keypoint_edge_width=2):\n",
    "\n",
    "  AAA = []\n",
    "  draw = ImageDraw.Draw(image)\n",
    "  im_width, im_height = image.size\n",
    "  keypoints = np.array(keypoints)\n",
    "  keypoints_x = [k[1] for k in keypoints]\n",
    "  keypoints_y = [k[0] for k in keypoints]\n",
    "  if use_normalized_coordinates:\n",
    "    keypoints_x = tuple([im_width * x for x in keypoints_x])\n",
    "    keypoints_y = tuple([im_height * y for y in keypoints_y])\n",
    "  if keypoint_scores is not None:\n",
    "    keypoint_scores = np.array(keypoint_scores)\n",
    "    valid_kpt = np.greater(keypoint_scores, min_score_thresh)\n",
    "  else:\n",
    "    valid_kpt = np.where(np.any(np.isnan(keypoints), axis=1),\n",
    "                         np.zeros_like(keypoints[:, 0]),\n",
    "                         np.ones_like(keypoints[:, 0]))\n",
    "  valid_kpt = [v for v in valid_kpt]\n",
    "\n",
    "  for keypoint_x, keypoint_y, valid in zip(keypoints_x, keypoints_y, valid_kpt):\n",
    "    if valid:\n",
    "      draw.ellipse([(keypoint_x - radius, keypoint_y - radius),\n",
    "                    (keypoint_x + radius, keypoint_y + radius)],\n",
    "                   outline=color, fill=color)\n",
    "      AAA.append([int(keypoint_x), int(keypoint_y)])\n",
    "\n",
    "  if keypoint_edges is not None:\n",
    "    for keypoint_start, keypoint_end in keypoint_edges:\n",
    "      if (keypoint_start < 0 or keypoint_start >= len(keypoints) or\n",
    "          keypoint_end < 0 or keypoint_end >= len(keypoints)):\n",
    "        continue\n",
    "      if not (valid_kpt[keypoint_start] and valid_kpt[keypoint_end]):\n",
    "        continue\n",
    "      edge_coordinates = [\n",
    "          keypoints_x[keypoint_start], keypoints_y[keypoint_start],\n",
    "          keypoints_x[keypoint_end], keypoints_y[keypoint_end]\n",
    "      ]\n",
    "      draw.line(\n",
    "          edge_coordinates, fill=keypoint_edge_color, width=keypoint_edge_width)\n",
    "  return AAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a49eda-8ee2-4aaa-bcd6-ae4039007132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def slope(x1, y1, x2, y2): # Line slope given two points:\n",
    "    return (y2-y1)/(x2-x1)\n",
    "\n",
    "def angle(s1, s2): \n",
    "    return math.degrees(math.atan((s2-s1)/(1+(s2*s1))))\n",
    "\n",
    "def for_cal_angle(c0, c1, c2):\n",
    "    lineA = ((AAA[c0][0], AAA[c0][1] ), (AAA[c1][0], AAA[c1][1] ))\n",
    "    lineB = ((AAA[c1][0], AAA[c1][1] ), (AAA[c2][0], AAA[c2][1] ))\n",
    "\n",
    "    slope1 = slope(lineA[0][0], lineA[0][1], lineA[1][0], lineA[1][1])\n",
    "    slope2 = slope(lineB[0][0], lineB[0][1], lineB[1][0], lineB[1][1])\n",
    "\n",
    "    ang = angle(slope1, slope2)\n",
    "    print('Angle in degrees = ', int(abs(ang)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791d5560-c659-4d77-888a-79bd6c56590f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMAGE_PATHS = [\n",
    "#     'C:/Users/84916/Desktop/cat_goc/1.jpg',\n",
    "#     'C:/Users/84916/Desktop/cat_goc/2.jpg',\n",
    "#     'C:/Users/84916/Desktop/cat_goc/3.jpg',\n",
    "#     'C:/Users/84916/Desktop/cat_goc/4.jpg',\n",
    "#     'C:/Users/84916/Desktop/cat_goc/c1.jpeg',\n",
    "#     'C:/Users/84916/Desktop/cat_goc/c2.jpeg',\n",
    "#     'C:/Users/84916/Desktop/cat_goc/c3.jpeg',\n",
    "#     'C:/Users/84916/Desktop/cat_goc/c4.jpeg',\n",
    "#     'C:/Users/84916/Desktop/cat_goc/c5.jpeg',\n",
    "#     'C:/Users/84916/Desktop/cat_goc/c6.jpeg',\n",
    "# ]\n",
    "# IMAGE_PATHS = ['C:/Users/84916/Desktop/cat_goc/3.jpg',]\n",
    "IMAGE_PATHS = ['C:/Users/84916/Desktop/cat_goc/c6.jpeg',]\n",
    "\n",
    "for i, img_path in enumerate(IMAGE_PATHS):\n",
    "    img_np = load_image_into_numpy_array(img_path)\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(img_np, 0),dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key:value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "    detections[\"num_detections\"] = num_detections\n",
    "    detections[\"detection_classes\"] = detections[\"detection_classes\"].astype(np.int64)\n",
    "    keypoints = None\n",
    "    keypoint_scores = None\n",
    "\n",
    "    if \"detection_keypoints\" in detections:\n",
    "        keypoints = detections['detection_keypoints']\n",
    "        keypoint_scores=detections['detection_keypoint_scores']\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = img_np.copy()\n",
    "    image_np_with_detections, AAA, BBB = draw_box(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            keypoints=keypoints,\n",
    "            keypoint_edges=[[0, 1],[1, 2], [2, 3], [3, 0]],\n",
    "            keypoint_scores=keypoint_scores,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=200,\n",
    "            min_score_thresh=0.1,\n",
    "            agnostic_mode=False,\n",
    "#             skip_boxes=False,\n",
    "            skip_boxes=True,\n",
    "            skip_labels=True,\n",
    "            skip_scores=True,\n",
    "            skip_track_ids=True)\n",
    "    \n",
    "\n",
    "\n",
    "    print(\"AAA\", AAA) #[[361.748623251915, 390.3252696990967], \n",
    "#                     # [39.32695023715496, 392.12050437927246], \n",
    "#                     # [33.55983607470989, 180.37547707557678], \n",
    "#                     # [369.11259055137634, 180.62534093856812]]\n",
    "\n",
    "#     print(\"BBB\", BBB) #[32.367591485381126, 176.74899101257324, 368.026682138443, 393.9006757736206]\n",
    "#     print(\"-\"*50)\n",
    "\n",
    "#     polygon = Polygon(AAA)\n",
    "#     s1 = polygon.area\n",
    "\n",
    "#     start_point = (BBB[0], BBB[1])\n",
    "#     end_point = (BBB[2], BBB[3])\n",
    "#     width_rec = end_point[0] - start_point[0]\n",
    "#     height_rec = end_point[1] - start_point[1]\n",
    "#     s2 = width_rec * height_rec\n",
    "\n",
    "#     print(\"OVERLAP:\", s1/s2)\n",
    "    cv2.imshow(str(i), cv2.resize(image_np_with_detections,(640, 640)))\n",
    "    \n",
    "    AAA_array = np.array(AAA)\n",
    "    x_min = min(AAA_array[:,0])\n",
    "    y_min = min(AAA_array[:,1])\n",
    "    x_max = max(AAA_array[:,0])\n",
    "    y_max = max(AAA_array[:,1])\n",
    "    \n",
    "    \n",
    "#     for p in AAA:\n",
    "#         cv2.circle(image_np_with_detections, p, 6, (0,255,255), 3)\n",
    "    \n",
    "#     cv2.rectangle(image_np_with_detections, (133, 369), (555, 779), (0,0,255), 3)\n",
    "#     cv2.imshow(\"VVV\", cv2.resize(image_np_with_detections,(640, 640)))\n",
    "\n",
    "    for_cal_angle(0,1,2)\n",
    "    for_cal_angle(1,2,3)\n",
    "    for_cal_angle(2,3,0)\n",
    "    for_cal_angle(3,0,1)\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfcc302-bf67-4410-8ba7-1ec9e9c9a86f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d06cae-41d4-462f-afc6-8647060c3552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd534a16-7f3c-4d57-8020-375f3043fdfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c002a23b-078b-4b4a-80b1-4eb8a9124d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import time\n",
    "import cv2\n",
    "import abc\n",
    "import collections\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image as Image\n",
    "import PIL.ImageColor as ImageColor\n",
    "import PIL.ImageDraw as ImageDraw\n",
    "import PIL.ImageFont as ImageFont\n",
    "import six\n",
    "import tensorflow.compat.v1 as tf\n",
    "import math\n",
    "import imutils\n",
    "\n",
    "from six.moves import range\n",
    "from six.moves import zip\n",
    "from object_detection.core import keypoint_ops\n",
    "from object_detection.core import standard_fields as fields\n",
    "from object_detection.utils import shape_utils\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from PIL import Image\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "PATH_TO_CFG = \"pipeline.config\"\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore('model/ckpt-21').expect_partial()\n",
    "PATH_TO_LABELS = \"label_map.pbtxt\"\n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n",
    "                                                                    use_display_name=True)\n",
    "_TITLE_LEFT_MARGIN = 10\n",
    "_TITLE_TOP_MARGIN = 10\n",
    "STANDARD_COLORS = [\n",
    "    'AliceBlue', 'Chartreuse', 'Aqua', 'Aquamarine', 'Azure', 'Beige', 'Bisque',\n",
    "    'BlanchedAlmond', 'BlueViolet', 'BurlyWood', 'CadetBlue', 'AntiqueWhite',\n",
    "    'Chocolate', 'Coral', 'CornflowerBlue', 'Cornsilk', 'Crimson', 'Cyan',\n",
    "    'DarkCyan', 'DarkGoldenRod', 'DarkGrey', 'DarkKhaki', 'DarkOrange',\n",
    "    'DarkOrchid', 'DarkSalmon', 'DarkSeaGreen', 'DarkTurquoise', 'DarkViolet',\n",
    "    'DeepPink', 'DeepSkyBlue', 'DodgerBlue', 'FireBrick', 'FloralWhite',\n",
    "    'ForestGreen', 'Fuchsia', 'Gainsboro', 'GhostWhite', 'Gold', 'GoldenRod',\n",
    "    'Salmon', 'Tan', 'HoneyDew', 'HotPink', 'IndianRed', 'Ivory', 'Khaki',\n",
    "    'Lavender', 'LavenderBlush', 'LawnGreen', 'LemonChiffon', 'LightBlue',\n",
    "    'LightCoral', 'LightCyan', 'LightGoldenRodYellow', 'LightGray', 'LightGrey',\n",
    "    'LightGreen', 'LightPink', 'LightSalmon', 'LightSeaGreen', 'LightSkyBlue',\n",
    "    'LightSlateGray', 'LightSlateGrey', 'LightSteelBlue', 'LightYellow', 'Lime',\n",
    "    'LimeGreen', 'Linen', 'Magenta', 'MediumAquaMarine', 'MediumOrchid',\n",
    "    'MediumPurple', 'MediumSeaGreen', 'MediumSlateBlue', 'MediumSpringGreen',\n",
    "    'MediumTurquoise', 'MediumVioletRed', 'MintCream', 'MistyRose', 'Moccasin',\n",
    "    'NavajoWhite', 'OldLace', 'Olive', 'OliveDrab', 'Orange', 'OrangeRed',\n",
    "    'Orchid', 'PaleGoldenRod', 'PaleGreen', 'PaleTurquoise', 'PaleVioletRed',\n",
    "    'PapayaWhip', 'PeachPuff', 'Peru', 'Pink', 'Plum', 'PowderBlue', 'Purple',\n",
    "    'Red', 'RosyBrown', 'RoyalBlue', 'SaddleBrown', 'Green', 'SandyBrown',\n",
    "    'SeaGreen', 'SeaShell', 'Sienna', 'Silver', 'SkyBlue', 'SlateBlue',\n",
    "    'SlateGray', 'SlateGrey', 'Snow', 'SpringGreen', 'SteelBlue', 'GreenYellow',\n",
    "    'Teal', 'Thistle', 'Tomato', 'Turquoise', 'Violet', 'Wheat', 'White',\n",
    "    'WhiteSmoke', 'Yellow', 'YellowGreen'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17df9972-a9ad-438f-a746-5c29eaad5f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(x1, y1, x2, y2): # Line slope given two points:\n",
    "    return (y2-y1)/(x2-x1)\n",
    "\n",
    "\n",
    "def angle(s1, s2):\n",
    "    return math.degrees(math.atan((s2-s1)/(1+(s2*s1))))\n",
    "\n",
    "\n",
    "def for_cal_angle(c0, c1, c2, AAA):\n",
    "    lineA = ((AAA[c0][0], AAA[c0][1] ), (AAA[c1][0], AAA[c1][1] ))\n",
    "    lineB = ((AAA[c1][0], AAA[c1][1] ), (AAA[c2][0], AAA[c2][1] ))\n",
    "\n",
    "    slope1 = slope(lineA[0][0], lineA[0][1], lineA[1][0], lineA[1][1])\n",
    "    slope2 = slope(lineB[0][0], lineB[0][1], lineB[1][0], lineB[1][1])\n",
    "\n",
    "    ang = angle(slope1, slope2)\n",
    "    print('Angle in degrees = ', int(abs(ang)))\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections\n",
    "\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "\n",
    "def draw_box(\n",
    "        image,\n",
    "        boxes,\n",
    "        classes,\n",
    "        scores,\n",
    "        category_index,\n",
    "        instance_masks=None,\n",
    "        instance_boundaries=None,\n",
    "        keypoints=None,\n",
    "        keypoint_scores=None,\n",
    "        keypoint_edges=None,\n",
    "        track_ids=None,\n",
    "        use_normalized_coordinates=False,\n",
    "        max_boxes_to_draw=20,\n",
    "        min_score_thresh=.5,\n",
    "        agnostic_mode=False,\n",
    "        line_thickness=4,\n",
    "        mask_alpha=.4,\n",
    "        groundtruth_box_visualization_color='black',\n",
    "        skip_boxes=False,\n",
    "        skip_scores=False,\n",
    "        skip_labels=False,\n",
    "        skip_track_ids=False):\n",
    "    # Create a display string (and color) for every box location, group any boxes\n",
    "    # that correspond to the same location.\n",
    "    box_to_display_str_map = collections.defaultdict(list)\n",
    "    box_to_color_map = collections.defaultdict(str)\n",
    "    box_to_instance_masks_map = {}\n",
    "    box_to_instance_boundaries_map = {}\n",
    "    box_to_keypoints_map = collections.defaultdict(list)\n",
    "    box_to_keypoint_scores_map = collections.defaultdict(list)\n",
    "    box_to_track_ids_map = {}\n",
    "    if not max_boxes_to_draw:\n",
    "        max_boxes_to_draw = boxes.shape[0]\n",
    "    for i in range(boxes.shape[0]):\n",
    "        if max_boxes_to_draw == len(box_to_color_map):\n",
    "            break\n",
    "        if scores is None or scores[i] > min_score_thresh:\n",
    "            box = tuple(boxes[i].tolist())\n",
    "            if instance_masks is not None:\n",
    "                box_to_instance_masks_map[box] = instance_masks[i]\n",
    "            if instance_boundaries is not None:\n",
    "                box_to_instance_boundaries_map[box] = instance_boundaries[i]\n",
    "            if keypoints is not None:\n",
    "                box_to_keypoints_map[box].extend(keypoints[i])\n",
    "            if keypoint_scores is not None:\n",
    "                box_to_keypoint_scores_map[box].extend(keypoint_scores[i])\n",
    "            if track_ids is not None:\n",
    "                box_to_track_ids_map[box] = track_ids[i]\n",
    "            if scores is None:\n",
    "                box_to_color_map[box] = groundtruth_box_visualization_color\n",
    "            else:\n",
    "                display_str = ''\n",
    "                if not skip_labels:\n",
    "                    if not agnostic_mode:\n",
    "                        if classes[i] in six.viewkeys(category_index):\n",
    "                            class_name = category_index[classes[i]]['name']\n",
    "                        else:\n",
    "                            class_name = 'N/A'\n",
    "                        display_str = str(class_name)\n",
    "                if not skip_scores:\n",
    "                    if not display_str:\n",
    "                        display_str = '{}%'.format(round(100 * scores[i]))\n",
    "                    else:\n",
    "                        display_str = '{}: {}%'.format(display_str, round(100 * scores[i]))\n",
    "                if not skip_track_ids and track_ids is not None:\n",
    "                    if not display_str:\n",
    "                        display_str = 'ID {}'.format(track_ids[i])\n",
    "                    else:\n",
    "                        display_str = '{}: ID {}'.format(display_str, track_ids[i])\n",
    "                box_to_display_str_map[box].append(display_str)\n",
    "                if agnostic_mode:\n",
    "                    box_to_color_map[box] = 'DarkOrange'\n",
    "                elif track_ids is not None:\n",
    "                    prime_multipler = _get_multiplier_for_color_randomness()\n",
    "                    box_to_color_map[box] = STANDARD_COLORS[\n",
    "                        (prime_multipler * track_ids[i]) % len(STANDARD_COLORS)]\n",
    "                else:\n",
    "                    box_to_color_map[box] = STANDARD_COLORS[\n",
    "                        classes[i] % len(STANDARD_COLORS)]\n",
    "\n",
    "    # Draw all boxes onto image.\n",
    "    for box, color in box_to_color_map.items():\n",
    "\n",
    "        ymin, xmin, ymax, xmax = box\n",
    "        if instance_masks is not None:\n",
    "            draw_mask_on_image_array(\n",
    "                image,\n",
    "                box_to_instance_masks_map[box],\n",
    "                color=color,\n",
    "                alpha=mask_alpha\n",
    "            )\n",
    "        if instance_boundaries is not None:\n",
    "            draw_mask_on_image_array(\n",
    "                image,\n",
    "                box_to_instance_boundaries_map[box],\n",
    "                color='red',\n",
    "                alpha=1.0\n",
    "            )\n",
    "        BBB = draw_bounding_box_on_image_array(\n",
    "            image,\n",
    "            ymin,\n",
    "            xmin,\n",
    "            ymax,\n",
    "            xmax,\n",
    "            color=color,\n",
    "            thickness=0 if skip_boxes else line_thickness,\n",
    "            display_str_list=box_to_display_str_map[box],\n",
    "            use_normalized_coordinates=use_normalized_coordinates)\n",
    "\n",
    "        if keypoints is not None:\n",
    "\n",
    "            keypoint_scores_for_box = None\n",
    "            if box_to_keypoint_scores_map:\n",
    "                keypoint_scores_for_box = box_to_keypoint_scores_map[box]\n",
    "            AAA = draw_keypoints_on_image_array(\n",
    "                image,\n",
    "                box_to_keypoints_map[box],\n",
    "                keypoint_scores_for_box,\n",
    "                min_score_thresh=min_score_thresh,\n",
    "                color=color,\n",
    "                radius=line_thickness / 2,\n",
    "                use_normalized_coordinates=use_normalized_coordinates,\n",
    "                keypoint_edges=keypoint_edges,\n",
    "                keypoint_edge_color=color,\n",
    "                keypoint_edge_width=line_thickness // 2)\n",
    "    try:\n",
    "        return image, AAA, BBB\n",
    "    except:\n",
    "        return image, [], []\n",
    "\n",
    "\n",
    "def draw_bounding_box_on_image_array(image,\n",
    "                                     ymin,\n",
    "                                     xmin,\n",
    "                                     ymax,\n",
    "                                     xmax,\n",
    "                                     color='red',\n",
    "                                     thickness=4,\n",
    "                                     display_str_list=(),\n",
    "                                     use_normalized_coordinates=True):\n",
    "    image_pil = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "    BBB = draw_bounding_box_on_image(image_pil, ymin, xmin, ymax, xmax, color,\n",
    "                                     thickness, display_str_list,\n",
    "                                     use_normalized_coordinates)\n",
    "    np.copyto(image, np.array(image_pil))\n",
    "    return BBB\n",
    "\n",
    "\n",
    "def draw_bounding_box_on_image(image,\n",
    "                               ymin,\n",
    "                               xmin,\n",
    "                               ymax,\n",
    "                               xmax,\n",
    "                               color='red',\n",
    "                               thickness=4,\n",
    "                               display_str_list=(),\n",
    "                               use_normalized_coordinates=True):\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    im_width, im_height = image.size\n",
    "    if use_normalized_coordinates:\n",
    "        (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n",
    "                                      ymin * im_height, ymax * im_height)\n",
    "    else:\n",
    "        (left, right, top, bottom) = (xmin, xmax, ymin, ymax)\n",
    "    if thickness > 0:\n",
    "        draw.line([(left, top), (left, bottom), (right, bottom), (right, top),\n",
    "                   (left, top)],\n",
    "                  width=thickness,\n",
    "                  fill=color)\n",
    "    BBB = [int(left), int(top), int(right), int(bottom)]\n",
    "    try:\n",
    "        font = ImageFont.truetype('arial.ttf', 24)\n",
    "    except IOError:\n",
    "        font = ImageFont.load_default()\n",
    "\n",
    "    # If the total height of the display strings added to the top of the bounding\n",
    "    # box exceeds the top of the image, stack the strings below the bounding box\n",
    "    # instead of above.\n",
    "    display_str_heights = [font.getsize(ds)[1] for ds in display_str_list]\n",
    "    # Each display_str has a top and bottom margin of 0.05x.\n",
    "    total_display_str_height = (1 + 2 * 0.05) * sum(display_str_heights)\n",
    "\n",
    "    if top > total_display_str_height:\n",
    "        text_bottom = top\n",
    "    else:\n",
    "        text_bottom = bottom + total_display_str_height\n",
    "    # Reverse list and print from bottom to top.\n",
    "    for display_str in display_str_list[::-1]:\n",
    "        text_width, text_height = font.getsize(display_str)\n",
    "        margin = np.ceil(0.05 * text_height)\n",
    "        draw.rectangle(\n",
    "            [(left, text_bottom - text_height - 2 * margin), (left + text_width,\n",
    "                                                              text_bottom)],\n",
    "            fill=color)\n",
    "        draw.text(\n",
    "            (left + margin, text_bottom - text_height - margin),\n",
    "            display_str,\n",
    "            fill='black',\n",
    "            font=font)\n",
    "        text_bottom -= text_height - 2 * margin\n",
    "\n",
    "    return BBB\n",
    "\n",
    "\n",
    "def draw_keypoints_on_image_array(image,\n",
    "                                  keypoints,\n",
    "                                  keypoint_scores=None,\n",
    "                                  min_score_thresh=0.5,\n",
    "                                  color='red',\n",
    "                                  radius=2,\n",
    "                                  use_normalized_coordinates=True,\n",
    "                                  keypoint_edges=None,\n",
    "                                  keypoint_edge_color='green',\n",
    "                                  keypoint_edge_width=2):\n",
    "    image_pil = Image.fromarray(np.uint8(image)).convert('RGB')\n",
    "    AAA = draw_keypoints_on_image(image_pil,\n",
    "                                  keypoints,\n",
    "                                  keypoint_scores=keypoint_scores,\n",
    "                                  min_score_thresh=min_score_thresh,\n",
    "                                  color=color,\n",
    "                                  radius=radius,\n",
    "                                  use_normalized_coordinates=use_normalized_coordinates,\n",
    "                                  keypoint_edges=keypoint_edges,\n",
    "                                  keypoint_edge_color=keypoint_edge_color,\n",
    "                                  keypoint_edge_width=keypoint_edge_width)\n",
    "    np.copyto(image, np.array(image_pil))\n",
    "    return AAA\n",
    "\n",
    "\n",
    "def draw_keypoints_on_image(image,\n",
    "                            keypoints,\n",
    "                            keypoint_scores=None,\n",
    "                            min_score_thresh=0.5,\n",
    "                            color='red',\n",
    "                            radius=2,\n",
    "                            use_normalized_coordinates=True,\n",
    "                            keypoint_edges=None,\n",
    "                            keypoint_edge_color='green',\n",
    "                            keypoint_edge_width=2):\n",
    "    AAA = []\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    im_width, im_height = image.size\n",
    "    keypoints = np.array(keypoints)\n",
    "    keypoints_x = [k[1] for k in keypoints]\n",
    "    keypoints_y = [k[0] for k in keypoints]\n",
    "    if use_normalized_coordinates:\n",
    "        keypoints_x = tuple([im_width * x for x in keypoints_x])\n",
    "        keypoints_y = tuple([im_height * y for y in keypoints_y])\n",
    "    if keypoint_scores is not None:\n",
    "        keypoint_scores = np.array(keypoint_scores)\n",
    "        valid_kpt = np.greater(keypoint_scores, min_score_thresh)\n",
    "    else:\n",
    "        valid_kpt = np.where(np.any(np.isnan(keypoints), axis=1),\n",
    "                             np.zeros_like(keypoints[:, 0]),\n",
    "                             np.ones_like(keypoints[:, 0]))\n",
    "    valid_kpt = [v for v in valid_kpt]\n",
    "\n",
    "    for keypoint_x, keypoint_y, valid in zip(keypoints_x, keypoints_y, valid_kpt):\n",
    "        if valid:\n",
    "#             draw.ellipse([(keypoint_x - radius, keypoint_y - radius),\n",
    "#                           (keypoint_x + radius, keypoint_y + radius)],\n",
    "#                          outline=color, fill=color)\n",
    "            AAA.append([int(keypoint_x), int(keypoint_y)])\n",
    "\n",
    "    if keypoint_edges is not None:\n",
    "        for keypoint_start, keypoint_end in keypoint_edges:\n",
    "            if (keypoint_start < 0 or keypoint_start >= len(keypoints) or\n",
    "                    keypoint_end < 0 or keypoint_end >= len(keypoints)):\n",
    "                continue\n",
    "            if not (valid_kpt[keypoint_start] and valid_kpt[keypoint_end]):\n",
    "                continue\n",
    "            edge_coordinates = [\n",
    "                keypoints_x[keypoint_start], keypoints_y[keypoint_start],\n",
    "                keypoints_x[keypoint_end], keypoints_y[keypoint_end]\n",
    "            ]\n",
    "            draw.line(\n",
    "                edge_coordinates, fill=keypoint_edge_color, width=keypoint_edge_width)\n",
    "    return AAA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20218099-213e-480d-be4a-bcbda1fc39e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\code\\venv_all\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:464: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "AAA [[413, 440], [430, 726], [226, 739], [245, 446]]\n",
      "Angle in degrees =  89\n",
      "Angle in degrees =  82\n",
      "Angle in degrees =  84\n",
      "Angle in degrees =  88\n"
     ]
    }
   ],
   "source": [
    "# IMAGE_PATHS = ['C:/Users/84916/Desktop/cat_goc/c3.jpeg', ]\n",
    "IMAGE_PATHS = ['C:/Users/84916/Desktop/cat_goc/p1.jpg', ]\n",
    "\n",
    "for i, img_path in enumerate(IMAGE_PATHS):\n",
    "    img_np = load_image_into_numpy_array(img_path)\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(img_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "    detections[\"num_detections\"] = num_detections\n",
    "    detections[\"detection_classes\"] = detections[\"detection_classes\"].astype(np.int64)\n",
    "    keypoints = None\n",
    "    keypoint_scores = None\n",
    "\n",
    "    if \"detection_keypoints\" in detections:\n",
    "        keypoints = detections['detection_keypoints']\n",
    "        keypoint_scores = detections['detection_keypoint_scores']\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = img_np.copy()\n",
    "    image_np_with_detections, AAA, BBB = draw_box(\n",
    "        image_np_with_detections,\n",
    "        detections['detection_boxes'],\n",
    "        detections['detection_classes'] + label_id_offset,\n",
    "        detections['detection_scores'],\n",
    "        category_index,\n",
    "        keypoints=keypoints,\n",
    "#         keypoint_edges=[[0, 1], [1, 2], [2, 3], [3, 0]],\n",
    "        keypoint_scores=keypoint_scores,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=200,\n",
    "        min_score_thresh=0.1,\n",
    "        agnostic_mode=False,\n",
    "        # skip_boxes=False,\n",
    "        skip_boxes=True,\n",
    "        skip_labels=True,\n",
    "        skip_scores=True,\n",
    "        skip_track_ids=True)\n",
    "\n",
    "    print(\"AAA\", AAA)  # [[361.748623251915, 390.3252696990967],\n",
    "    #                     # [39.32695023715496, 392.12050437927246],\n",
    "    #                     # [33.55983607470989, 180.37547707557678],\n",
    "    #                     # [369.11259055137634, 180.62534093856812]]\n",
    "    for_cal_angle(0, 1, 2, AAA)\n",
    "    for_cal_angle(1, 2, 3, AAA)\n",
    "    for_cal_angle(2, 3, 0, AAA)\n",
    "    for_cal_angle(3, 0, 1, AAA)\n",
    "    \n",
    "    pts1 = np.float32(AAA)\n",
    "    pts2 = np.float32([[0, 0], [640, 0], [640, 480], [0, 480]])\n",
    "    matrix = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    result = cv2.warpPerspective(image_np_with_detections, matrix, (640, 480))\n",
    "    \n",
    "#     cv2.imshow(str(i), cv2.resize(image_np_with_detections, (640, 640)))\n",
    "    cv2.imshow(str(i)+\"_\"+str(i), cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "    bbox = cv2.cvtColor(image_np_with_detections[BBB[1]:BBB[3], BBB[0]:BBB[2]], cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow(\"box\", bbox)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "384fdc43-2486-4182-b23c-488de3803472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 1)\n",
      "0 []\n"
     ]
    }
   ],
   "source": [
    "#check anh photo\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.use('TkAgg')\n",
    "# IMAGE_PATHS = ['C:/Users/84916/Desktop/cat_goc/1.jpg',\n",
    "#                'C:/Users/84916/Desktop/cat_goc/2.jpg',\n",
    "#                'C:/Users/84916/Desktop/cat_goc/3.jpg',\n",
    "#                'C:/Users/84916/Desktop/cat_goc/4.jpg',\n",
    "#                'C:/Users/84916/Desktop/cat_goc/c1.jpeg',\n",
    "#                'C:/Users/84916/Desktop/cat_goc/c2.jpeg',\n",
    "#                'C:/Users/84916/Desktop/cat_goc/c3.jpeg',\n",
    "#                'C:/Users/84916/Desktop/cat_goc/c4.jpeg',\n",
    "#                'C:/Users/84916/Desktop/cat_goc/c5.jpeg',\n",
    "#                'C:/Users/84916/Desktop/cat_goc/c6.jpeg',\n",
    "#                'C:/Users/84916/Desktop/cat_goc/p1.jpg',\n",
    "#                'C:/Users/84916/Desktop/cat_goc/p2.jpg',\n",
    "#                'C:/Users/84916/Desktop/cat_goc/p3.jpg',\n",
    "#                'C:/Users/84916/Desktop/cat_goc/p4.jpg',\n",
    "#                'C:/Users/84916/Desktop/cat_goc/p5.jpg',\n",
    "#               ]\n",
    "              \n",
    "IMAGE_PATHS = ['C:/Users/84916/Desktop/cat_goc/p2.jpg']\n",
    "# IMAGE_PATHS = ['C:/Users/84916/Desktop/cat_goc/c5.jpeg', ]\n",
    "\n",
    "for i, img_path in enumerate(IMAGE_PATHS):\n",
    "    img_np = load_image_into_numpy_array(img_path)\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(img_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "    detections[\"num_detections\"] = num_detections\n",
    "    detections[\"detection_classes\"] = detections[\"detection_classes\"].astype(np.int64)\n",
    "    keypoints = None\n",
    "    keypoint_scores = None\n",
    "\n",
    "    if \"detection_keypoints\" in detections:\n",
    "        keypoints = detections['detection_keypoints']\n",
    "        keypoint_scores = detections['detection_keypoint_scores']\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = img_np.copy()\n",
    "    image_np_with_detections, AAA, BBB = draw_box(\n",
    "        image_np_with_detections,\n",
    "        detections['detection_boxes'],\n",
    "        detections['detection_classes'] + label_id_offset,\n",
    "        detections['detection_scores'],\n",
    "        category_index,\n",
    "        keypoints=keypoints,\n",
    "        keypoint_edges=[[0, 1], [1, 2], [2, 3], [3, 0]],\n",
    "        keypoint_scores=keypoint_scores,\n",
    "        use_normalized_coordinates=True,\n",
    "        max_boxes_to_draw=200,\n",
    "        min_score_thresh=0.1,\n",
    "        agnostic_mode=False,\n",
    "        # skip_boxes=False,\n",
    "        skip_boxes=True,\n",
    "        skip_labels=True,\n",
    "        skip_scores=True,\n",
    "        skip_track_ids=True)\n",
    "\n",
    "    bbox = cv2.cvtColor(image_np_with_detections[BBB[1]:BBB[3], BBB[0]:BBB[2]], cv2.COLOR_BGR2RGB)\n",
    "    bbox_hsv = cv2.cvtColor(bbox, cv2.COLOR_BGR2HSV)\n",
    "    bbox_hsv_saturation = bbox_hsv[:,:,1]\n",
    "    \n",
    "    histr1 = cv2.calcHist([bbox_hsv_saturation],[0],None,[256],[0,256])\n",
    "    print(histr1.shape)\n",
    "    # show the plotting graph of an image\n",
    "    \n",
    "#     plt.plot(histr1)\n",
    "    \n",
    "    print(i, AAA)\n",
    "    \n",
    "    cv2.imshow(str(i), bbox)\n",
    "    cv2.imshow(str(i)+\"_HSV\", bbox_hsv_saturation)\n",
    "#     plt.show()\n",
    "    \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "9dce387c-2111-4f0e-8007-d09dbb8fb1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284, 176)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbox_hsv_saturation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d949c9f-65b1-41e3-b47b-2b3a94b8d61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95613605]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "  \n",
    "# importing library for plotting\n",
    "from matplotlib import pyplot as plt\n",
    "path_img = 'D:/Code/Tima_Onbroading/Tima_API/result.jpg'\n",
    "# path_img = 'C:/Users/84916/Desktop/cat_goc/c5.jpeg'\n",
    "# reads an input image\n",
    "img = cv2.imread(path_img)\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "hsv_sat = hsv[:, :, 1]\n",
    "  \n",
    "# find frequency of pixels in range 0-255\n",
    "histr = cv2.calcHist([hsv_sat],[0],None,[256],[0,256])\n",
    "print(sum(histr[0:50]) / sum(histr[0:]))\n",
    "# show the plotting graph of an image\n",
    "plt.plot(histr)\n",
    "plt.show()\n",
    "cv2.imshow(\"aaaa\", hsv_sat)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52250179-8b36-4067-a827-997ce2f4a677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
